{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics on the output data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from the sqlite database to the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import lizard\n",
    "import subprocess as sub\n",
    "from pylibsrcml import srcml\n",
    "import os\n",
    "import re \n",
    "import xml.etree.ElementTree as et \n",
    "import warnings\n",
    "from sqlite3 import connect\n",
    "from argparse import ArgumentParser\n",
    "from configparser import ConfigParser\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# database = '../data/IoT.db'\n",
    "# database = '../data/TinyVul.db'\n",
    "database = \"/Users/guru/research/VulnMiner.db\"\n",
    "conn= connect(database)\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "dfp = pd.read_sql_query(\"SELECT * FROM project\", con=conn)\n",
    "dfs = pd.read_sql_query(\"SELECT * FROM statement\", con=conn)\n",
    "dff = pd.read_sql_query(\"SELECT * FROM function\", con=conn)\n",
    "\n",
    "if not os.path.exists(\"figure\"):\n",
    "    os.mkdir(\"figure\")\n",
    "dfs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting subburset plot from the frequency of category, name and cwe types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplt = dfs[['category', 'name', 'cwe']].groupby(['category', 'name', 'cwe'], group_keys=False).size().reset_index(name='count')\n",
    "\n",
    "dfplt['category'] = dfplt.apply(lambda row: row['category'] \n",
    "if row['category']==row['name'] or row['name']=='-' \n",
    "else row['name'], axis=1)\n",
    "dfplt = dfplt.drop(labels=['name'], axis=1)\n",
    "\n",
    "fig = px.sunburst(dfplt, \n",
    "    path=['category', 'cwe'],\n",
    "    values='count', \n",
    "    color_continuous_scale='Blues',\n",
    "    color='count',\n",
    ")\n",
    "# fig.write_image(\"figure/vul_statistics.pdf\")\n",
    "# fig.update_traces(hovertemplate='%{label}<br>%{customdata}')\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,)\n",
    "fig.show()\n",
    "# save the figure manually, the below code takes ages\n",
    "# fig.write_image(\"../figure/vul_statistics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"../figure/vul_statistics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplt.sort_values(by=['count'], ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 vulnerabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top10 = dfplt.sort_values(by=['count'], ascending=False).head(10).reset_index(drop=True)\n",
    "print(tabulate(df_top10, headers='keys', tablefmt='psql'))\n",
    "df_top10.to_latex(\"../result/top10.tex\", index=False, caption=\"Top 10 CWEs in IoT code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs.context.head(200).str.len().plot(kind='bar')\n",
    "pd.Series(sorted(list(dfs.context.head(20).str.len()))).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_unusual_statements(statements, min_len, max_len, df):\n",
    "    \"\"\"\" \n",
    "    # https://peps.python.org/pep-0007/\n",
    "    # https://www.python.org/dev/peps/pep-0007/ \n",
    "\n",
    "    \"\"\"\n",
    "    filtered_statements = []\n",
    "    for statement in statements:\n",
    "        if len(statement) >= min_len and len(statement) <= max_len:\n",
    "            filtered_statements.append(statement)\n",
    "   \n",
    "    # take size of the vul statements as basis\n",
    "    df = pd.Series(statements)   \n",
    "    df = df.str.len()\n",
    "    \n",
    "    stat_sizes =  list(df[df.between(max_len, min_len)].reset_index(drop=True))\n",
    "    \n",
    "    sample_size = 5 if len(stat_sizes)>5 else len(stat_sizes)-1\n",
    "    stat_sizes = random.sample(set(stat_sizes), sample_size)\n",
    "    return stat_sizes\n",
    "\n",
    "\n",
    "# standard variables:\n",
    "max_len = 151  #TODO: double check pep standards\n",
    "\n",
    "# TODO: check min_len as well, otherwise the below code unnessesarily checks one extra condition \n",
    "# because there is no any statement/fun with len below that. \n",
    "# for min_len (eg, 7 characters)\n",
    "min_len = dfs.context.str.len().sort_values(ascending=False).reset_index(drop=True).min()\n",
    "\n",
    "\n",
    "lines = dff.code[0].splitlines()\n",
    "stat_sizes = filter_unusual_statements(lines, max_len, min_len, dfs)\n",
    "stat_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency of the vulnerabilities and benign samples at \n",
    "    - statement-level \n",
    "    - function-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for project-wise distribution\n",
    "# projects = list(dfs.project.unique())\n",
    "\n",
    "# for project in projects:\n",
    "#     print(project)\n",
    "#     df = dfs[dfs.project == project]\n",
    "#     print(df.shape)\n",
    "#     # print(df.cwe.value_counts())\n",
    "#     # print(df.category.value_counts())\n",
    "#     print('----------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a latex table from the statistics of projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_latex(df, file):\n",
    "    \"\"\"\n",
    "    save the dataframe as latex table\n",
    "    \"\"\"\n",
    "    styler = df.style\n",
    "    # styler.applymap_index(lambda v: \"font-weight: bold;\", axis=\"index\")\n",
    "    styler.applymap_index(lambda v: \"font-weight: bold;\", axis=\"columns\")\n",
    "    res = styler.to_latex(convert_css=True, column_format='|l|l|r|')\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        f.write(res)\n",
    "    return res\n",
    "\n",
    "# make class binary type benign/vulnerable\n",
    "dfs_binary = dfs.copy()\n",
    "dfs_binary.loc[dfs_binary.cwe!=\"Benign\", 'cwe'] = \"Vulnerable\"\n",
    "dfs_binary['project'] = dfs_binary.project.str.split('/').str[-1]\n",
    "\n",
    "prj_stat = dfs_binary.groupby(['project', 'cwe']).size().reset_index(name='count')\n",
    "prj_s = prj_stat.groupby(['project', 'cwe']).sum()\n",
    "\n",
    "res = tabulate(save_latex(prj_s, '../result/project_stat.tex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_binary = dff.copy()\n",
    "dff_binary.loc[dff_binary.cwe!=\"Benign\", 'cwe'] = \"Vulnerable\"\n",
    "dff_binary['project'] = dff_binary.project.str.split('/').str[-1]\n",
    "\n",
    "prj_fun = dff_binary.groupby(['project', 'cwe']).size().reset_index(name='count')\n",
    "prj_f = prj_fun.groupby(['project', 'cwe']).sum()\n",
    "# prj_f['total'] = prj_f.groupby('project').sum()\n",
    "# prj_f['ratio'] = prj_f['count']/prj_f['total']\n",
    "prj_f = prj_f.reset_index()\n",
    "prj_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_f = prj_f.rename(columns={'cwe':'cwef', 'count':'#function','project':'projectf'})\n",
    "prj_stat = prj_stat.rename(columns={'count':'#statement'})\n",
    "\n",
    "df_dist = pd.concat([prj_stat, prj_f], axis=1, join='inner')\n",
    "df_dist = df_dist.sort_values(by=['#statement'], ascending=False)\n",
    "df_dist = df_dist.drop(columns=['projectf', 'cwef'], axis=1)\n",
    "df_dist = df_dist.set_index(['project', 'cwe']).unstack()\n",
    "df_dist = df_dist.append(df_dist.sum().rename('TOTAL'))\n",
    "df_dist.reset_index().to_latex('../result/project-stat.tex', index=False, )\n",
    "# df_dist.append(df_dist.sum().tolist(), ignore_index=True)\n",
    "df_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total #statements: {df_dist[-1:].T.reset_index()['TOTAL'][0:2].sum()}\")\n",
    "print(f\"Total #functions: {df_dist[-1:].T.reset_index()['TOTAL'][2:4].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "37798 + 5984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_sflat = prj_s.reset_index()\n",
    "prj_sflat = prj_sflat.pivot(index='project', columns='cwe', values='count')\n",
    "# prj_sflat.reset_index().to_latex('../result/project_stat_flat.tex', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class binary type benign/vulnerable\n",
    "dff_binary = dff.copy()\n",
    "dff_binary.loc[dff_binary.cwe!=\"Benign\", 'cwe'] = \"Vulnerable\"\n",
    "\n",
    "prj_ff = dff_binary.groupby(['project', 'cwe']).size().reset_index(name='count')\n",
    "prj_f = prj_ff.groupby(['cwe']).sum().sort_values(by='count', ascending=False).reset_index()\n",
    "prj_f = prj_f[prj_f.cwe != 'Benign'].head(10)\n",
    "# print(prj_f.to_latex(index=False, caption='Top 10 CWEs', label='Top 10 CWEs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['cwe'] = dff.cwe.str.replace(r\"\\['|']\", \"\",regex=True)\n",
    "dfs_cwe = dfs.cwe.value_counts().reset_index(name='#statements')\n",
    "\n",
    "dff_cwe = dff.cwe.value_counts().reset_index(name='#functions')\n",
    "\n",
    "dfs_cwe = dfs_cwe.rename(columns={'index':'cwe'})\n",
    "dff_cwe = dff_cwe.rename(columns={'index':'cwe'})\n",
    "df_cwe_count = pd.concat([dfs_cwe, dff_cwe], axis=1).head(10)\n",
    "df_cwe_count = df_cwe_count.astype({\"#functions\": int})\n",
    "df_cwe_count.to_latex('../result/cwe-top-10.tex', index=False)\n",
    "df_cwe_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the description of the function-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_describe = dff_binary.drop(\n",
    "    labels=['top_nesting_level', 'fan_in', 'fan_out', 'general_fan_out', 'content', 'long_name', 'fun_name', 'full_parameters', 'code'],\n",
    "    axis=1, \n",
    "    errors='ignore').describe().T\n",
    "\n",
    "df_freq = df_describe.reset_index().rename(columns={'index': 'features'})\n",
    "df_freq = df_freq.drop(labels=['count'], axis=1)\n",
    "\n",
    "# shortening the project URL to project name only \n",
    "df_freq['top'] = df_freq.apply(lambda row:row['top'].split('/')[-1] if '/' in row['top'] else row['top'], axis=1)\n",
    "\n",
    "# The freq is the most common value’s frequency. The top is the most common value.\n",
    "print(df_freq[~df_freq.features.isin(['file'])].to_latex(\n",
    "    index=False,\n",
    "    column_format='rrrrr', \n",
    "    label='Function Statistics', \n",
    "    caption='Function Statistics')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Size of statements: {len(dfs.context)}')\n",
    "print(f'Size of unique statements: {dfs.context.nunique()}')\n",
    "\n",
    "print(f'\\nSize of functions: {len(dff.code)}')\n",
    "print(f'Size of unique functions: {dff.code.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-specific: Convert hyperparameters list to latex table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperpara2latex(yaml_file):\n",
    "    \"\"\"\n",
    "    load the yaml file and return a dictionary\n",
    "    \"\"\"\n",
    "    config = {}\n",
    "    cols = ['hyperparameter', 'value']\n",
    "    \n",
    "    ext = Path(yaml_file).suffix.replace('.', '') \n",
    "    \n",
    "    with open(yaml_file, \"r\") as stream:\n",
    "        try:\n",
    "            config = yaml.safe_load(stream)\n",
    "            print(type(config))\n",
    "            df = pd.DataFrame([config['dnn']]).T.reset_index()\n",
    "            print(df.to_latex(index=False, \n",
    "                    header=cols, \n",
    "                    #   column_format='|l|l|', \n",
    "                    label='Hyperparameter Settings', \n",
    "                    caption='Hyperparameter Settings'))\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "\n",
    "config = hyperpara2latex('../config/classifier.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokens count of function-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "fun_token_count = [len(simple_preprocess(x)) for x in dff.code]\n",
    "stat_token_count = [len(simple_preprocess(x)) for x in dfs.context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_token_count_short = [x for x in fun_token_count if x<=1024]\n",
    "pd.Series(fun_token_count_short).plot.hist(bins=20)\n",
    "plt.xlabel('#tokens')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.title('Function Token Count Distribution')\n",
    "plt.savefig('../figure/fun_token_count.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(stat_token_count).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(fun_token_count).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(stat_token_count).plot.hist(bins=20, alpha=0.8)\n",
    "plt.xlabel('#tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('../figure/stat_token_count.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs1 = dfs[dfs.context.str.len()<151]\n",
    "stat_char_len = [len(x) for x in dfs1.context if len(x)>10]\n",
    "ax = pd.Series(stat_char_len).plot.hist(bins=20, xlabel='#chars', ylabel='#statements',alpha=0.8)\n",
    "plt.xlabel('#tokens')\n",
    "plt.ylabel('Frequency')\n",
    "fighist = ax.get_figure()\n",
    "fighist.savefig('../figure/statement-charlen.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(stat_char_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.describe().T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vulcode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "770d70f40277e0fadd6bc1f7a5fecfd799eee3cbb57c500ccfb48eb07fd2c1ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
